#!/usr/bin/env python3
"""
Main CLI entry point for Clinical RAG system.
"""

import os
import sys
import argparse
from pathlib import Path

# Set environment variable for ZenML on macOS
os.environ['OBJC_DISABLE_INITIALIZE_FORK_SAFETY'] = 'YES'

from pipelines.document_ingestion_pipeline import pdf_processing_pipeline
from pipelines.response_generation_pipeline import clinical_generation_pipeline
from pipelines.simple_generation_pipeline import simple_clinical_generation_pipeline
from utils.search import ClinicalRAGSearcher
from utils.database import DatabaseManager
from utils.config import DATA_DIR


def cmd_ingest(args):
    """Run the PDF ingestion pipeline."""
    pdf_path = args.pdf_path
    
    if not Path(pdf_path).exists():
        print(f"Error: PDF file not found: {pdf_path}")
        sys.exit(1)
    
    print(f"Processing PDF: {pdf_path}")
    print(f"Chunk size: {args.chunk_size}, Overlap: {args.overlap}")
    print(f"Model: {args.model}")
    
    try:
        pipeline_run = pdf_processing_pipeline(
            pdf_path=str(pdf_path),
            chunk_size=args.chunk_size,
            overlap=args.overlap,
            model_name=args.model
        )
        
        # Get the result from the storage step
        step_output = pipeline_run.steps["store_embeddings_in_database"].output.load()
        
        if step_output['success']:
            print(f"‚úÖ Successfully processed {Path(pdf_path).name}")
            print(f"üì¶ Stored {step_output['stored_count']} chunks and embeddings")
            stats = step_output['database_stats']
            total_embeddings = sum(e['total_embeddings'] for e in stats['embeddings']) if stats['embeddings'] else 0
            print(f"üìä Database now contains {stats['documents']['total_docs']} documents, {total_embeddings} total embeddings")
        else:
            print(f"‚ùå Processing failed: {step_output['error']}")
            sys.exit(1)
            
    except Exception as e:
        print(f"‚ùå Pipeline error: {e}")
        sys.exit(1)


def cmd_search(args):
    """Run a search query."""
    try:
        searcher = ClinicalRAGSearcher()
        
        print(f"üîç Searching for: {args.query}")
        print(f"Top {args.top_k} results (similarity ‚â• {args.threshold})")
        
        results = searcher.search_similar_chunks(
            query=args.query,
            top_k=args.top_k,
            similarity_threshold=args.threshold,
            section_filter=args.section,
            enhance_query=not args.no_enhance
        )
        
        if results:
            print(f"\n=== Found {len(results)} results ===\n")
            for i, result in enumerate(results, 1):
                print(f"Result {i} (Similarity: {result['similarity']:.3f})")
                print(f"Document: {result['filename']}")
                print(f"Section: {result['section_type']}")
                
                text = result['text']
                if len(text) > 300:
                    text = text[:300] + "..."
                
                print(f"Content: {text}")
                print("-" * 80)
        else:
            print("No results found.")
            
    except Exception as e:
        print(f"‚ùå Search error: {e}")
        sys.exit(1)


def cmd_ask(args):
    """Ask a clinical question using RAG (Retrieval + Generation)."""
    try:
        searcher = ClinicalRAGSearcher()
        
        print(f"üîç Searching for: {args.query}")
        print(f"Top {args.top_k} results (similarity ‚â• {args.threshold})")
        
        # Retrieve relevant chunks
        results = searcher.search_similar_chunks(
            query=args.query,
            top_k=args.top_k,
            similarity_threshold=args.threshold,
            section_filter=args.section,
            enhance_query=not args.no_enhance
        )
        
        if not results:
            print("No relevant clinical information found.")
            print("ü§ñ Generating simple response without context...\n")
            
            try:
                # Use simple generation pipeline without context
                pipeline_run = simple_clinical_generation_pipeline(
                    query=args.query,
                    model_name=args.model,
                    temperature=args.temperature,
                    output_format="detailed"
                )
                
                # Get the output from the last step
                pipeline_result = pipeline_run.steps["format_final_cli_output"].output.load()
                
                if pipeline_result['success']:
                    print(pipeline_result['cli_output'])
                else:
                    print(f"‚ùå Generation failed: {pipeline_result['error']}")
                    
            except Exception as e:
                print(f"‚ùå Simple generation error: {e}")
            return
            
        print(f"‚úÖ Found {len(results)} relevant chunks")
        print("ü§ñ Running generation pipeline...\n")
        
        try:
            # Convert search results to format expected by pipeline
            chunks_for_generation = []
            for result in results:
                chunks_for_generation.append({
                    'text': result['text'],
                    'similarity': result['similarity'],
                    'section_type': result['section_type'],
                    'filename': result['filename']
                })
            
            # Run the clinical generation pipeline
            pipeline_run = clinical_generation_pipeline(
                query=args.query,
                retrieved_chunks=chunks_for_generation,
                model_name=args.model,
                temperature=args.temperature,
                output_format="detailed",
                include_full_metadata=True
            )
            
            # Get the output from the last step
            pipeline_result = pipeline_run.steps["format_final_cli_output"].output.load()
            
            if pipeline_result['success']:
                # Pipeline handles all formatting, just print the result
                print(pipeline_result['cli_output'])
            else:
                print(f"‚ùå Generation pipeline failed: {pipeline_result['error']}")
                print("\nüìÑ Retrieved information (fallback):")
                _show_chunks(results)
                
        except Exception as e:
            print(f"‚ùå Pipeline execution error: {e}")
            print("\nüìÑ Retrieved information (fallback):")
            _show_chunks(results)
            
    except Exception as e:
        print(f"‚ùå Query error: {e}")
        sys.exit(1)


def _show_chunks(results):
    """Helper function to display retrieved chunks."""
    for i, result in enumerate(results, 1):
        print(f"Result {i} (Similarity: {result['similarity']:.3f})")
        print(f"Document: {result['filename']}")
        print(f"Section: {result['section_type']}")
        
        text = result['text']
        if len(text) > 300:
            text = text[:300] + "..."
        
        print(f"Content: {text}")
        print("-" * 80)


def cmd_status(args):
    """Check database status."""
    try:
        db_manager = DatabaseManager()
        
        # Test connection
        status = db_manager.test_connection()
        if status['success']:
            print("‚úÖ Database connection successful")
            print(f"PostgreSQL version: {status['postgresql_version']}")
            print(f"pgvector test distance: {status['pgvector_test_distance']}")
        else:
            print(f"‚ùå Database connection failed: {status['error']}")
            sys.exit(1)
        
        # Get statistics
        stats = db_manager.get_statistics()
        print(f"\nüìä Database Statistics:")
        print(f"Documents: {stats['documents']['total_docs']} total, {stats['documents']['completed_docs']} completed")
        print(f"Chunks: {stats['chunks']['total_chunks']}")
        
        if stats['embeddings']:
            for embedding_stat in stats['embeddings']:
                print(f"Embeddings ({embedding_stat['model_name']}): {embedding_stat['total_embeddings']}")
        else:
            print("Embeddings: 0")
            
    except Exception as e:
        print(f"‚ùå Status check error: {e}")
        sys.exit(1)


def main():
    """Main CLI function."""
    parser = argparse.ArgumentParser(
        description="Clinical RAG system - Process clinical PDFs and search semantically",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Process a PDF
  python run.py ingest data/raw/Achilles_Pain.pdf
  
  # Search for raw chunks (retrieval only)
  python run.py search "What exercises help with pain?"
  
  # Ask clinical question with AI response (full RAG)
  python run.py ask "What exercises help with Achilles tendon pain?"
  
  # Check database status
  python run.py status
        """
    )
    
    subparsers = parser.add_subparsers(dest='command', help='Available commands')
    
    # Ingest command
    ingest_parser = subparsers.add_parser('ingest', help='Process PDF into embeddings')
    ingest_parser.add_argument('pdf_path', help='Path to PDF file to process')
    ingest_parser.add_argument('--chunk-size', type=int, default=1000, help='Chunk size in characters (default: 1000)')
    ingest_parser.add_argument('--overlap', type=int, default=200, help='Overlap between chunks (default: 200)')
    ingest_parser.add_argument('--model', default='all-MiniLM-L6-v2', help='Sentence transformer model (default: all-MiniLM-L6-v2)')
    ingest_parser.set_defaults(func=cmd_ingest)
    
    # Search command (retrieval only)
    search_parser = subparsers.add_parser('search', help='Search for information (retrieval only)')
    search_parser.add_argument('query', help='Search query')
    search_parser.add_argument('--top-k', type=int, default=5, help='Number of results to return (default: 5)')
    search_parser.add_argument('--threshold', type=float, default=0.3, help='Minimum similarity threshold (default: 0.3)')
    search_parser.add_argument('--section', help='Filter by section type (treatment, diagnosis, etc.)')
    search_parser.add_argument('--no-enhance', action='store_true', help='Disable query enhancement')
    search_parser.set_defaults(func=cmd_search)
    
    # Ask command (full RAG)
    ask_parser = subparsers.add_parser('ask', help='Ask clinical question with AI response (RAG)')
    ask_parser.add_argument('query', help='Clinical question')
    ask_parser.add_argument('--top-k', type=int, default=5, help='Number of chunks to retrieve (default: 5)')
    ask_parser.add_argument('--threshold', type=float, default=0.3, help='Minimum similarity threshold (default: 0.3)')
    ask_parser.add_argument('--section', help='Filter by section type (treatment, diagnosis, etc.)')
    ask_parser.add_argument('--no-enhance', action='store_true', help='Disable query enhancement')
    ask_parser.add_argument('--model', default='llama3.2:3b', help='Ollama model for generation (default: llama3.2:3b)')
    ask_parser.add_argument('--temperature', type=float, default=0.1, help='Generation temperature 0.0-1.0 (default: 0.1)')
    ask_parser.set_defaults(func=cmd_ask)
    
    # Status command
    status_parser = subparsers.add_parser('status', help='Check database status')
    status_parser.set_defaults(func=cmd_status)
    
    # Parse and execute
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        sys.exit(1)
    
    args.func(args)


if __name__ == "__main__":
    main()